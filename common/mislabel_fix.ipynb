{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중국어 mislabel 수정 (좌표 순서 -- 좌상단 우상단 우하단 좌하단)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_path = '/data/ephemeral/code/data/chinese_receipt/ufo/train.json'\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def correct_points(points):\n",
    "    # points를 NumPy 배열로 변환\n",
    "    points = np.array(points)\n",
    "\n",
    "    left_points = points[np.argsort(points[:, 0])][:2]\n",
    "    right_points = points[np.argsort(points[:, 0])][-2:]\n",
    "\n",
    "    # 좌측 점들 중 y 값이 작은 점이 좌상단, 큰 점이 좌하단\n",
    "    top_left = left_points[np.argmin(left_points[:, 1])]\n",
    "    bottom_left = left_points[np.argmax(left_points[:, 1])]\n",
    "\n",
    "    # 우측 점들 중 y 값이 작은 점이 우상단, 큰 점이 우하단\n",
    "    top_right = right_points[np.argmin(right_points[:, 1])]\n",
    "    bottom_right = right_points[np.argmax(right_points[:, 1])]\n",
    "\n",
    "    # 올바른 순서로 재배치\n",
    "    corrected_points = [top_left.tolist(), top_right.tolist(), bottom_right.tolist(), bottom_left.tolist()]\n",
    "    \n",
    "    return corrected_points\n",
    "\n",
    "# 레이블 순서 확인 및 수정\n",
    "for image_id, image_info in data.get('images', {}).items():\n",
    "    for word_id, word_info in image_info.get('words', {}).items():\n",
    "        original_points = word_info['points']\n",
    "        corrected_points = correct_points(original_points)\n",
    "        \n",
    "        # 원래 점과 수정된 점을 비교하여 변경사항이 있는지 확인\n",
    "        if not np.array_equal(np.array(original_points), np.array(corrected_points)):\n",
    "            print(f\"Correcting points for image: {image_id}, word: {word_id}\")\n",
    "            word_info['points'] = corrected_points\n",
    "\n",
    "# 수정된 JSON 파일 저장\n",
    "corrected_json_path = '/data/ephemeral/code/data/chinese_receipt/ufo/train_corrected.json'\n",
    "with open(corrected_json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Corrected JSON saved to: {corrected_json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일본어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_path = '/data/ephemeral/code/data/japanese_receipt/ufo/train.json'\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def correct_points(points):\n",
    "    # points를 NumPy 배열로 변환\n",
    "    points = np.array(points)\n",
    "\n",
    "    left_points = points[np.argsort(points[:, 0])][:2]\n",
    "    right_points = points[np.argsort(points[:, 0])][-2:]\n",
    "\n",
    "    # 좌측 점들 중 y 값이 작은 점이 좌상단, 큰 점이 좌하단\n",
    "    top_left = left_points[np.argmin(left_points[:, 1])]\n",
    "    bottom_left = left_points[np.argmax(left_points[:, 1])]\n",
    "\n",
    "    # 우측 점들 중 y 값이 작은 점이 우상단, 큰 점이 우하단\n",
    "    top_right = right_points[np.argmin(right_points[:, 1])]\n",
    "    bottom_right = right_points[np.argmax(right_points[:, 1])]\n",
    "\n",
    "    # 올바른 순서로 재배치\n",
    "    corrected_points = [top_left.tolist(), top_right.tolist(), bottom_right.tolist(), bottom_left.tolist()]\n",
    "    \n",
    "    return corrected_points\n",
    "\n",
    "# 레이블 순서 확인 및 수정\n",
    "for image_id, image_info in data.get('images', {}).items():\n",
    "    for word_id, word_info in image_info.get('words', {}).items():\n",
    "        original_points = word_info['points']\n",
    "        corrected_points = correct_points(original_points)\n",
    "        \n",
    "        # 원래 점과 수정된 점을 비교하여 변경사항이 있는지 확인\n",
    "        if not np.array_equal(np.array(original_points), np.array(corrected_points)):\n",
    "            print(f\"Correcting points for image: {image_id}, word: {word_id}\")\n",
    "            word_info['points'] = corrected_points\n",
    "\n",
    "# 수정된 JSON 파일 저장\n",
    "corrected_json_path = '/data/ephemeral/code/data/japanese_receipt/ufo/train_corrected.json'\n",
    "with open(corrected_json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Corrected JSON saved to: {corrected_json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 태국어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_path = '/data/ephemeral/code/data/thai_receipt/ufo/train.json'\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def correct_points(points):\n",
    "    # points를 NumPy 배열로 변환\n",
    "    points = np.array(points)\n",
    "\n",
    "    left_points = points[np.argsort(points[:, 0])][:2]\n",
    "    right_points = points[np.argsort(points[:, 0])][-2:]\n",
    "\n",
    "    # 좌측 점들 중 y 값이 작은 점이 좌상단, 큰 점이 좌하단\n",
    "    top_left = left_points[np.argmin(left_points[:, 1])]\n",
    "    bottom_left = left_points[np.argmax(left_points[:, 1])]\n",
    "\n",
    "    # 우측 점들 중 y 값이 작은 점이 우상단, 큰 점이 우하단\n",
    "    top_right = right_points[np.argmin(right_points[:, 1])]\n",
    "    bottom_right = right_points[np.argmax(right_points[:, 1])]\n",
    "\n",
    "    # 올바른 순서로 재배치\n",
    "    corrected_points = [top_left.tolist(), top_right.tolist(), bottom_right.tolist(), bottom_left.tolist()]\n",
    "    \n",
    "    return corrected_points\n",
    "\n",
    "# 레이블 순서 확인 및 수정\n",
    "for image_id, image_info in data.get('images', {}).items():\n",
    "    for word_id, word_info in image_info.get('words', {}).items():\n",
    "        original_points = word_info['points']\n",
    "        corrected_points = correct_points(original_points)\n",
    "        \n",
    "        # 원래 점과 수정된 점을 비교하여 변경사항이 있는지 확인\n",
    "        if not np.array_equal(np.array(original_points), np.array(corrected_points)):\n",
    "            print(f\"Correcting points for image: {image_id}, word: {word_id}\")\n",
    "            word_info['points'] = corrected_points\n",
    "\n",
    "# 수정된 JSON 파일 저장\n",
    "corrected_json_path = '/data/ephemeral/code/data/thai_receipt/ufo/train_corrected.json'\n",
    "with open(corrected_json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Corrected JSON saved to: {corrected_json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 베트남어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# JSON 파일 경로\n",
    "json_path = '/data/ephemeral/code/data/vietnamese_receipt/ufo/train.json'\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def correct_points(points):\n",
    "    # points를 NumPy 배열로 변환\n",
    "    points = np.array(points)\n",
    "\n",
    "    left_points = points[np.argsort(points[:, 0])][:2]\n",
    "    right_points = points[np.argsort(points[:, 0])][-2:]\n",
    "\n",
    "    # 좌측 점들 중 y 값이 작은 점이 좌상단, 큰 점이 좌하단\n",
    "    top_left = left_points[np.argmin(left_points[:, 1])]\n",
    "    bottom_left = left_points[np.argmax(left_points[:, 1])]\n",
    "\n",
    "    # 우측 점들 중 y 값이 작은 점이 우상단, 큰 점이 우하단\n",
    "    top_right = right_points[np.argmin(right_points[:, 1])]\n",
    "    bottom_right = right_points[np.argmax(right_points[:, 1])]\n",
    "\n",
    "    # 올바른 순서로 재배치\n",
    "    corrected_points = [top_left.tolist(), top_right.tolist(), bottom_right.tolist(), bottom_left.tolist()]\n",
    "    \n",
    "    return corrected_points\n",
    "\n",
    "# 레이블 순서 확인 및 수정\n",
    "for image_id, image_info in data.get('images', {}).items():\n",
    "    for word_id, word_info in image_info.get('words', {}).items():\n",
    "        original_points = word_info['points']\n",
    "        corrected_points = correct_points(original_points)\n",
    "        \n",
    "        # 원래 점과 수정된 점을 비교하여 변경사항이 있는지 확인\n",
    "        if not np.array_equal(np.array(original_points), np.array(corrected_points)):\n",
    "            print(f\"Correcting points for image: {image_id}, word: {word_id}\")\n",
    "            word_info['points'] = corrected_points\n",
    "\n",
    "# 수정된 JSON 파일 저장\n",
    "corrected_json_path = '/data/ephemeral/code/data/vietnamese_receipt/ufo/train_corrected.json'\n",
    "with open(corrected_json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Corrected JSON saved to: {corrected_json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lines label 없애기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSON 파일 경로 설정\n",
    "input_json_path = '/data/ephemeral/code/data/japanese_receipt/ufo/train_corrected.json'  # 원본 JSON 파일 경로\n",
    "output_json_path = '/data/ephemeral/code/data/japanese_receipt/ufo/train_corrected_v2.json'  # 수정된 JSON 파일 경로\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# transcription이 빈 문자열인 words 삭제\n",
    "for image_key, image_value in data['images'].items():\n",
    "    if 'words' in image_value:\n",
    "        words_to_delete = [word_key for word_key, word_info in image_value['words'].items() \n",
    "                           if 'transcription' in word_info and word_info['transcription'] == \"\" or word_info['transcription'] == \"----------\"]\n",
    "        \n",
    "        # 찾은 키들을 삭제\n",
    "        for word_key in words_to_delete:\n",
    "            del image_value['words'][word_key]\n",
    "\n",
    "# 수정된 JSON 파일 저장\n",
    "with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"transcription이 빈 문자열인 words가 삭제된 JSON 파일이 {output_json_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
